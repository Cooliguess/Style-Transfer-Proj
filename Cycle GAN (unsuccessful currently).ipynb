{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631fa200-7f68-4f68-a29b-102ce1678446",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "6995d4e4-4bb3-4d1c-b529-45913a2b3bff",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: keras in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (2.12.0)\n",
      "Collecting tensorflow==2.11.0\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "     -------------------------------------- 266.3/266.3 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.54.2)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.3.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.9/895.9 kB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.7.4.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (23.5.26)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (67.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (0.31.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.4.0)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (23.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.24.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (16.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow==2.11.0) (0.35.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (2.19.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (4.7.2)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.26.15)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (6.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow==2.11.0) (3.2.2)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.12.0\n",
      "    Uninstalling tensorflow-intel-2.12.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.12.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "Successfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0\n",
      "Requirement already satisfied: numpy in c:\\users\\dheki\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np \n",
    "!pip install matplotlib\n",
    "!pip install keras\n",
    "!pip install tensorflow==2.11.0\n",
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "318535b8-4fc0-41a3-8980-d49cf0a199d4",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "816a1e22-ba8c-486a-a683-2e1bae2043ff",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\530279034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\keras\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_version_tuple\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_built_version_tuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\h5py\\version.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_h5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5.pyx\u001b[0m in \u001b[0;36minit h5py.h5\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97225032-f028-430e-bfaf-19f581f4e9c5",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "f13a6f9b-b4f3-495b-9055-6a84627cfd91",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\3823798717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#from keras.models import Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#from tensorflow.python.keras.models import Input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstancenormalization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\keras\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_version_tuple\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_built_version_tuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TheOne\\lib\\site-packages\\h5py\\version.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_h5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5.pyx\u001b[0m in \u001b[0;36minit h5py.h5\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from tensorflow.python.keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from random import random\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "#from tfa.layers import InstanceNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0efc750a-74c0-4aba-9581-66fa42f1b846",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "696414ea-040f-48ae-a84d-0b06fd03e141",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\1581404591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'horse2zebra/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# load dataset A\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdataA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'trainA/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mdataAB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'testA/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdataA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataAB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\1581404591.py\u001b[0m in \u001b[0;36mload_images\u001b[1;34m(path, size)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# enumerate filenames in directory, assume all are images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m# load and resize the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256)):\n",
    "    data_list = list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in listdir(path):\n",
    "        # load and resize the image\n",
    "        pixels = load_img(path + filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)\n",
    "# dataset path\n",
    "path = 'horse2zebra/'\n",
    "# load dataset A\n",
    "dataA1 = load_images(path + 'trainA/')\n",
    "dataAB = load_images(path + 'testA/')\n",
    "dataA = vstack((dataA1, dataAB))\n",
    "print('Loaded dataA: ', dataA.shape)\n",
    "# load dataset B\n",
    "dataB1 = load_images(path + 'trainB/')\n",
    "dataB2 = load_images(path + 'testB/')\n",
    "dataB = vstack((dataB1, dataB2))\n",
    "print('Loaded dataB: ', dataB.shape)\n",
    "# save as compressed numpy array\n",
    "filename = 'horse2zebra.npz'\n",
    "np.savez_compressed(filename, dataA, dataB)\n",
    "print('Saved dataset: ', filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "616f8608-daee-40c1-8dbe-5d4be13617ba",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "18c5b07c-5d59-4d9e-b3fe-726551fb2ec9",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\3336729027.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load and plot the prepared dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# load the face dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'horse2zebra_256.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# load and plot the prepared dataset\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "# load the face dataset\n",
    "data = load('horse2zebra.npz')\n",
    "dataA, dataB = data['arr_0'], data['arr_1']\n",
    "print('Loaded: ', dataA.shape, dataB.shape)\n",
    "# plot source images\n",
    "n_samples = 3\n",
    "for i in range(n_samples):\n",
    "    pyplot.subplot(2, n_samples, 1 + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(dataA[i].astype('uint8'))\n",
    "# plot target image\n",
    "for i in range(n_samples):\n",
    "    pyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(dataB[i].astype('uint8'))\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b351add1-ba4e-4756-bd33-0ff3a260b54a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "341cf2bb-5910-49dc-a024-e416f7706b7a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, patch_out)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0827a9fd-7dd4-46b6-86b4-32b81b2001c4",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "833dd724-6453-4ced-91fb-1139f6e3cd6a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# generator a resnet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # first layer convolutional layer\n",
    "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # second convolutional layer\n",
    "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    # concatenate merge channel-wise with input layer\n",
    "    g = Concatenate()([g, input_layer])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ee3823-a924-4f27-929e-a19e762da819",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "bd7a2a52-1328-4a32-b133-6bfdc2e38bc4",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(image_shape, n_resnet=9):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # c7s1-64\n",
    "    g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d128\n",
    "    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d256\n",
    "    g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # R256\n",
    "    for _ in range(n_resnet):\n",
    "        g = resnet_block(256, g)\n",
    "    # u128\n",
    "    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # u64\n",
    "    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # c7s1-3\n",
    "    g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2315afd-abc3-4344-bf55-fbc89015d890",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "19ccbc52-84be-4edb-a5c4-26b752f1030d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# define a composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    # ensure the model we're updating is trainable\n",
    "    g_model_1.trainable = True\n",
    "    # mark discriminator as not trainable\n",
    "    d_model.trainable = False\n",
    "    # mark other generator model as not trainable\n",
    "    g_model_2.trainable = False\n",
    "    # discriminator element\n",
    "    input_gen = Input(shape=image_shape)\n",
    "    gen1_out = g_model_1(input_gen)\n",
    "    output_d = d_model(gen1_out)\n",
    "    # identity element\n",
    "    input_id = Input(shape=image_shape)\n",
    "    output_id = g_model_1(input_id)\n",
    "    # forward cycle\n",
    "    output_f = g_model_2(gen1_out)\n",
    "    # backward cycle\n",
    "    gen2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen2_out)\n",
    "    # define model graph\n",
    "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    # define optimization algorithm configuration\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    # compile model with weighting of least squares loss and L1 loss\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 1],\n",
    "        optimizer=opt)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a25d2d32-17bd-4cf5-86c1-23691a0664be",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "31ab48df-0a44-49da-89de-c43f6da76432",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "    # load the dataset\n",
    "    data = load(filename)\n",
    "    # unpack arrays\n",
    "    X1, X2 = data['arr_0'], data['arr_1']\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X1 = (X1 - 127.5) / 127.5\n",
    "    X2 = (X2 - 127.5) / 127.5\n",
    "    return [X1, X2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b8eac3e-1947-42cf-8aca-b2d411d732c5",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "eaa5fbd1-109a-4866-bee5-a51d991eb3c9",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33853888-edb3-4b9e-a671-ee9f1d1f943d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "f8592262-1b07-4676-88cb-c89e1d3a26d8",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(dataset)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eaef932-d1a3-4cee-8b49-e06a7640de56",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "05f361ff-b3f3-4107-9dbc-30e4bc2ade0a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# save the generator models to file\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "    # save the first generator model\n",
    "    filename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
    "    g_model_AtoB.save(filename1)\n",
    "    # save the second generator model\n",
    "    filename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n",
    "    g_model_BtoA.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30e1ad20-a4e3-4376-a4ac-03270bb1cfb4",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "4e74a556-829c-4fe5-9e52-e18f5f3826f6",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
    "    # select a sample of input images\n",
    "    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
    "    # generate translated images\n",
    "    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_in = (X_in + 1) / 2.0\n",
    "    X_out = (X_out + 1) / 2.0\n",
    "    # plot real images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(2, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_in[i])\n",
    "    # plot translated image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_out[i])\n",
    "    # save plot to file\n",
    "    filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89cc3e51-25a9-4887-8359-dceb7558a11f",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "f7fe3340-f72d-431a-a1ee-9f4574af737f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# update image pool for fake images\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            # use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # replace an existing image and use replaced image\n",
    "            ix = randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return asarray(selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7c5b71c-6cea-4695-b660-25c1f35f6d92",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "4c64b334-99ff-46d4-8236-ae26bfb8be12",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# train cyclegan models\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA,\n",
    "dataset):\n",
    "    # define properties of the training run\n",
    "    n_epochs, n_batch, = 100, 1\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model_A.output_shape[1]\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # prepare image pool for fakes\n",
    "    poolA, poolB = list(), list()\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "        # update fakes from pool\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        # update generator B->A via adversarial and cycle loss\n",
    "        g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA,\n",
    "            X_realA, X_realB, X_realA])\n",
    "        # update discriminator for A -> [real/fake]\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        # update generator A->B via adversarial and cycle loss\n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB,\n",
    "            X_realB, X_realA, X_realB])\n",
    "        # update discriminator for B -> [real/fake]\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        # summarize performance\n",
    "        print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2,\n",
    "            dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "        # evaluate the model performance every so often\n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "            # plot A->B translation\n",
    "            summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
    "            # plot B->A translation\n",
    "            summarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
    "        if (i+1) % (bat_per_epo * 5) == 0:\n",
    "            # save the models\n",
    "            save_models(i, g_model_AtoB, g_model_BtoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f89769b-3798-4a28-b7b6-e359ca8f8fc7",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0f129c24-1ead-418d-835c-01c335058635",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (1187, 256, 256, 3) (1474, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomNormal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\2451016838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# generator: A -> B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mg_model_AtoB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# generator: B -> A\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mg_model_BtoA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\1041069090.py\u001b[0m in \u001b[0;36mdefine_generator\u001b[1;34m(image_shape, n_resnet)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_resnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# weight initialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# image input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0min_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomNormal' is not defined"
     ]
    }
   ],
   "source": [
    "# load image data\n",
    "dataset = load_real_samples('horse2zebra.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22f1b725-5762-4428-b132-df09994eb2de",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "f969354b-a187-4253-a36d-0eb0dad4e6ed",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (1187, 256, 256, 3) (1474, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'InstanceNormalization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\2637238503.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loaded'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# load the models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mcust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'InstanceNormalization'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mmodel_AtoB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'g_model_AtoB_089025.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mmodel_BtoA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'g_model_BtoA_089025.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'InstanceNormalization' is not defined"
     ]
    }
   ],
   "source": [
    "def load_real_samples(filename):\n",
    "    # load the dataset\n",
    "    data = load(filename)\n",
    "    # unpack arrays\n",
    "    X1, X2 = data['arr_0'], data['arr_1']\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X1 = (X1 - 127.5) / 127.5\n",
    "    X2 = (X2 - 127.5) / 127.5\n",
    "    return [X1, X2]\n",
    "    # select a random sample of images from the dataset\n",
    "def select_sample(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    return X\n",
    "    # plot the image, the translation, and the reconstruction\n",
    "def show_plot(imagesX, imagesY1, imagesY2):\n",
    "    images = vstack((imagesX, imagesY1, imagesY2))\n",
    "    titles = ['Real', 'Generated', 'Reconstructed']\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    images = (images + 1) / 2.0\n",
    "    # plot images row by row\n",
    "    for i in range(len(images)):\n",
    "        # define subplot\n",
    "        pyplot.subplot(1, len(images), 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(images[i])\n",
    "        # title\n",
    "        pyplot.title(titles[i])\n",
    "    pyplot.show()\n",
    "\n",
    "# load dataset\n",
    "A_data, B_data = load_real_samples('horse2zebra.npz')\n",
    "print('Loaded', A_data.shape, B_data.shape)\n",
    "# load the models\n",
    "cust = {'InstanceNormalization': InstanceNormalization}\n",
    "model_AtoB = load_model('g_model_AtoB_089025.h5', cust)\n",
    "model_BtoA = load_model('g_model_BtoA_089025.h5', cust)\n",
    "# plot A->B->A\n",
    "A_real = select_sample(A_data, 1)\n",
    "B_generated = model_AtoB.predict(A_real)\n",
    "A_reconstructed = model_BtoA.predict(B_generated)\n",
    "show_plot(A_real, B_generated, A_reconstructed)\n",
    "# plot B->A->B\n",
    "B_real = select_sample(B_data, 1)\n",
    "A_generated = model_BtoA.predict(B_real)\n",
    "B_reconstructed = model_AtoB.predict(A_generated)\n",
    "show_plot(B_real, A_generated, B_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec35a8d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\1507942427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpixels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# load the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mimage_src\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'horse2zebra/trainA/n02381460_541.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m# load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mcust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'InstanceNormalization'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\1507942427.py\u001b[0m in \u001b[0;36mload_image\u001b[1;34m(filename, size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# load and resize the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m# convert to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_img' is not defined"
     ]
    }
   ],
   "source": [
    "def load_image(filename, size=(256,256)):\n",
    "    # load and resize the image\n",
    "    pixels = load_img(filename, target_size=size)\n",
    "    # convert to numpy array\n",
    "    pixels = img_to_array(pixels)\n",
    "    # transform in a sample\n",
    "    pixels = expand_dims(pixels, 0)\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    pixels = (pixels - 127.5) / 127.5\n",
    "    return pixels\n",
    "# load the image\n",
    "image_src = load_image('horse2zebra/trainA/n02381460_541.jpg')\n",
    "# load the model\n",
    "cust = {'InstanceNormalization': InstanceNormalization}\n",
    "model_AtoB = load_model('g_model_AtoB_100895.h5', cust)\n",
    "# translate image\n",
    "image_tar = model_AtoB.predict(image_src)\n",
    "# scale from [-1,1] to [0,1]\n",
    "image_tar = (image_tar + 1) / 2.0\n",
    "# plot the translated image\n",
    "pyplot.imshow(image_tar[0])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3de6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f1426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "TheOne",
   "language": "python",
   "name": "theone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
